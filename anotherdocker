FROM python:3.11-slim

# Install JDK 11 and required tools
RUN apt-get update && \
    apt-get install -y openjdk-11-jre-headless wget curl && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Set environment variables
ENV PYSPARK_VERSION=3.5.0
ENV SPARK_HOME=/opt/spark
ENV PATH=$PATH:$SPARK_HOME/bin
ENV PYTHONPATH=/app
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

# Install Spark
RUN wget -q https://archive.apache.org/dist/spark/spark-${PYSPARK_VERSION}/spark-${PYSPARK_VERSION}-bin-hadoop3.tgz && \
    tar xzf spark-${PYSPARK_VERSION}-bin-hadoop3.tgz && \
    mv spark-${PYSPARK_VERSION}-bin-hadoop3 /opt/spark && \
    rm spark-${PYSPARK_VERSION}-bin-hadoop3.tgz

# Add BigQuery Spark connector
RUN wget -q https://repo1.maven.org/maven2/com/google/cloud/spark/spark-bigquery-with-dependencies_2.12/0.32.0/spark-bigquery-with-dependencies_2.12-0.32.0.jar -P /opt/spark/jars/

WORKDIR /app

# Copy all files from project root
COPY . .

# Install Python package and dependencies
RUN pip install --no-cache-dir -e .

# Make entrypoint executable
RUN chmod +x /app/vertex_entrypoint.sh

ENTRYPOINT ["/app/vertex_entrypoint.sh"]

=====================
